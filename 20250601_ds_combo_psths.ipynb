{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f42228-33d9-4dad-ad6b-49e8b4073627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import scipy\n",
    "from src.dataset import SESSION_SUBJECT_RECORDING, SUBJECT_PROBE_DATASET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme('paper')\n",
    "\n",
    "def load_ds_data(session_id):\n",
    "    ds_data_path = f'data/{session_id}/{session_id}_DS_TYPE12.mat'\n",
    "    file = scipy.io.loadmat(ds_data_path)\n",
    "    ds1sup = file['kType1sup'].flatten().astype('bool')\n",
    "    ds2sup = file['kType2sup'].flatten().astype('bool')\n",
    "    sample = file['samplesDS'].flatten()\n",
    "    ds1_sample = sample[ds1sup] - 1 # matlab to python index\n",
    "    ds2_sample = sample[ds2sup] - 1\n",
    "    return ds1_sample, ds2_sample   # time in LFP samples\n",
    "\n",
    "def ca3_cell_ids(session_id):\n",
    "    subject_id, recording_id = SESSION_SUBJECT_RECORDING[session_id]\n",
    "    ca3_dataset = SUBJECT_PROBE_DATASET[(subject_id, 'AP2')]\n",
    "    cell_info_path = f'ref/features_ca1_ca3dg_good.csv'\n",
    "    cell_info = pd.read_csv(cell_info_path)\n",
    "    cell_info = cell_info.loc[cell_info['dataset'] == ca3_dataset].drop(columns='dataset')\n",
    "    cell_info = cell_info.loc[cell_info['recording'] == recording_id].drop(columns='recording')\n",
    "    cell_info = cell_info.loc[cell_info['location'] == 'CA3'].drop(columns='location')\n",
    "    return np.array(cell_info['id'])\n",
    "\n",
    "def load_spike_data(session_id, cell_ids):\n",
    "    spike_cell_path = f'data/{session_id}/{session_id}_AP2_spike_clusters.npy'\n",
    "    spike_time_path = f'data/{session_id}/{session_id}_AP2_spike_times.npy'\n",
    "    spike_cell_ids = np.load(spike_cell_path).squeeze()\n",
    "    spike_times = np.load(spike_time_path).squeeze()\n",
    "    cell_id_mask = np.isin(spike_cell_ids, cell_ids)\n",
    "    spike_cell_ids = spike_cell_ids[cell_id_mask]\n",
    "    spike_times = spike_times[cell_id_mask]\n",
    "    spike_times = spike_times // 12\n",
    "    return spike_cell_ids, spike_times\n",
    "\n",
    "def load_ds_combos(session_id):\n",
    "    ds1_sample, ds2_sample = load_ds_data(session_id)\n",
    "    cell_ids = ca3_cell_ids(session_id)\n",
    "    ds1_time, ds2_time = load_ds_data(session_id)\n",
    "    ds_time = sorted([(t, 1) for t in ds1_time] + [(t, 2) for t in ds2_time])\n",
    "    ds_time, ds_type = np.array(ds_time).T\n",
    "    combo_isi = np.diff(ds_time)\n",
    "    ds_time, prev_ds_time = ds_time[1:], ds_time[:-1]\n",
    "    ds_type, prev_ds_type = ds_type[1:], ds_type[:-1]\n",
    "    combo_type = np.zeros_like(combo_isi, dtype='int')\n",
    "    combo_masks = [\n",
    "        (prev_ds_type == 1) & (ds_type == 1),\n",
    "        (prev_ds_type == 1) & (ds_type == 2),\n",
    "        (prev_ds_type == 2) & (ds_type == 1),\n",
    "        (prev_ds_type == 2) & (ds_type == 2),\n",
    "    ]\n",
    "    for n, mask in enumerate(combo_masks):\n",
    "        combo_type[mask] = n\n",
    "    return ds_time, combo_isi, combo_type\n",
    "\n",
    "def make_psth(session_id):\n",
    "    cell_ids = ca3_cell_ids(session_id)\n",
    "    ds_time, combo_isi, combo_type = load_ds_combos(session_id)\n",
    "    spike_ids, spike_times = load_spike_data(session_id, cell_ids)\n",
    "    n_samples = 2500 # must divide by 2\n",
    "    n_events = len(combo_type)\n",
    "    n_cells = len(cell_ids)\n",
    "    ds_psth = np.zeros((n_cells, n_events, n_samples), dtype='int')\n",
    "    spike_counts = []\n",
    "    for i in range(n_cells):\n",
    "        cell_spike_times = spike_times[spike_ids == cell_ids[i]]\n",
    "        cell_spike_times = cell_spike_times[cell_spike_times < ds_time[-1]]\n",
    "        spike_mask = np.zeros(ds_time[-1], dtype='int')\n",
    "        spike_mask[cell_spike_times] = 1\n",
    "        for j in range(n_events):\n",
    "            t = ds_time[j]\n",
    "            t_start = t - n_samples//2\n",
    "            t_stop = t + n_samples//2\n",
    "            if t_start < 0 or len(spike_mask) < t_stop:\n",
    "                ds_psth[i, j, :] += 0\n",
    "                continue\n",
    "            ds_psth[i, j, :] += spike_mask[t_start:t_stop]\n",
    "        spike_counts.append(len(cell_spike_times))\n",
    "    return cell_ids, spike_counts, ds_time, ds_psth, combo_isi, combo_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b31640c-432d-4789-acdf-e2e06f32df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_list = list(SESSION_SUBJECT_RECORDING.keys())\n",
    "result_dict = {}\n",
    "for session_id in session_list:\n",
    "    cell_ids, spike_count, ds_time, ds_psth, combo_isi, combo_type = make_psth(session_id)\n",
    "    result_dict[session_id] = {\n",
    "        'cell_id': cell_ids,\n",
    "        'spike_count': spike_count,\n",
    "        'ds_time': ds_time,\n",
    "        'ds_combo': combo_type,\n",
    "        'ds_isi': combo_isi,\n",
    "        'ds_psth': ds_psth,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b73d53f-cb93-43fe-9601-903fc87575eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(result_dict, 'ds_aligned_spikes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4080627-d840-4a27-80a0-9125b3f21472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
